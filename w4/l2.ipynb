{"cells":[{"cell_type":"markdown","source":["# Synthetic Data Generation"],"metadata":{"id":"JJ-fRoeqBWOG"},"id":"JJ-fRoeqBWOG"},{"cell_type":"code","execution_count":null,"id":"d16df99d","metadata":{"id":"d16df99d"},"outputs":[],"source":["# importing necessary libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","## Synthetic Data Generation\n","## This part of the starter code generates a synthetic regression dataset that\n","## will be used for comparing Ridge and Lasso regression. The output is\n","## governed by a polynomial y= w_0+w_1x+w_2x^2+...+w_7x^7. x is generated \n","## randomly from a uniform distribution. We have also defined the w vector to \n","## obtain the outputs. The dependent variable of training dataset is slightly \n","## corrupted by adding some noise sampled from a normal distribution. You can \n","## play around with this code to understand the dataset, but this is not the lab's focus.\n","## The code could also be implemented using Numpy Polynomial Library.\n","\n","# fix the seed for the random function\n","np.random.seed(2)\n","\n","# define the size of the train and test sets\n","train_size=25\n","test_size=50\n","\n","## listing the independent and dependent variables which makes it easy to use with \n","## data frames later\n","i_v=[\"X_1\", \"X_2\", \"X_3\", \"X_4\", \"X_5\", \"X_6\", \"X_7\"]\n","d_v=[\"Y\"]\n","\n","# define the coefficients of the polynomial\n","w_opt=np.array([1, 0, 2, 0, 0, 0, 0])\n","\n","# create an array of numbers sampled from a uniform distribution for the training set\n","x = np.sort(np.random.uniform(low=-5, high=5, size=train_size))\n","\n","# creating the training data frame and appending the independent variables\n","train_data = pd.DataFrame()\n","train_data[\"X_1\"] = x\n","train_data[\"X_2\"] = x**2\n","train_data[\"X_3\"] = x**3\n","train_data[\"X_4\"] = x**4\n","train_data[\"X_5\"] = x**5\n","train_data[\"X_6\"] = x**6\n","train_data[\"X_7\"] = x**7\n","\n","# sample a random noise vector\n","epislon = np.random.normal(loc=0.0, scale=30, size=train_size)\n","\n","# estimate the training data output. This will serve as the ground truth.\n","train_data[\"Y\"] = train_data.dot(w_opt)+epislon\n","\n","# create an array of numbers sampled from a uniform distribution for the test set\n","x = np.sort(np.random.uniform(low=-4, high=4, size=test_size))\n","\n","# creating the test data frame and appending the independent variables\n","test_data = pd.DataFrame()\n","test_data[\"X_1\"] = x\n","test_data[\"X_2\"] = x**2\n","test_data[\"X_3\"] = x**3\n","test_data[\"X_4\"] = x**4\n","test_data[\"X_5\"] = x**5\n","test_data[\"X_6\"] = x**6\n","test_data[\"X_7\"] = x**7\n","\n","# estimate the test data output. This will serve as the ground truth.\n","test_data[\"Y\"] = test_data.dot(w_opt)\n","\n","# ploting the training and test data\n","plt.figure(1)\n","plt.scatter(train_data[[\"X_1\"]], train_data[[\"Y\"]], c=\"red\", label='train data')\n","plt.scatter(test_data[[\"X_1\"]], test_data[[\"Y\"]], c=\"blue\", label='test data')\n","plt.xlabel('X')\n","plt.ylabel('Y')\n","plt.legend()\n","plt.title('Train and Test Data')"]},{"cell_type":"markdown","source":["# Ridge Regression with Cross Validation (1 point)"],"metadata":{"id":"pw-_qRVvBdGh"},"id":"pw-_qRVvBdGh"},{"cell_type":"code","source":["## We will use the generated data to try Ridge regression and determine the optimal\n","## alpha value. Read about the RidgeCV class from\n","## https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n","## and describe the following Parameters and attributes of the class\n","## \n","## alphas:\n","##\n","## cv:\n","##\n","## store_cv_values:\n","##\n","## cv_values_\n","##\n","## coef_\n","##\n","## alpha_\n","\n","from sklearn.linear_model import RidgeCV\n","\n","# Define a range of alpha from 1e-2 to 100 increasing in multiples of 10.\n","# <add your code here>\n","\n","# Define the number of cross validation folds\n","# <add your code here>\n","\n","## Create an instance of the regression model using the parameters defined above\n","# <add your code here>\n","\n","## Fit the model to the training set. Remember that we are performing\n","## multi-variate regression. The number of independent variables is > 1\n","# <add your code here>\n","\n","## Obtain the value of the estimated regularization parameter alpha\n","# <add your code here>\n","\n","## Display the coefficients of the regressor (weight vector)\n","# <add your code here>\n","\n","## Compute the predictions for the training data and save it in a variable\n","## named y_pred_tr_ridge\n","# <add your code here>\n","\n","## Compute the predictions for the test data and save it in a variable\n","## named y_pred_ridge\n","# <add your code here>"],"metadata":{"id":"CYs34Sob3uiM"},"id":"CYs34Sob3uiM","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Lasso Regression with Cross Validation (1 point)"],"metadata":{"id":"liXUeCXiGshv"},"id":"liXUeCXiGshv"},{"cell_type":"code","source":["## We will use the generated data to try Lasso regression and determine the optimal\n","## alpha value. Read about the LassoCV class from\n","## https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n","## and describe the following Parameters and attributes of the class\n","## \n","## alphas:\n","##\n","## cv:\n","##\n","## coef_\n","##\n","## alpha_\n","\n","from sklearn.linear_model import LassoCV\n","\n","# Define a range of alpha from 1e-2 to 100 increasing in multiples of 10.\n","# <add your code here>\n","\n","# Define the number of cross validation folds\n","# <add your code here>\n","\n","## Create an instance of the regression model using the parameters defined above\n","# <add your code here>\n","\n","## Fit the model to the training set. Remember that we are performing\n","## multi-variate regression. The number of independent variables is > 1\n","# <add your code here>\n","\n","## Obtain the value of the estimated regularization parameter alpha\n","# <add your code here>\n","\n","## Display the coefficients of the regressor (weight vector)\n","# <add your code here>\n","\n","## Compute the predictions for the training data and save it in a variable\n","## named y_pred_tr_lasso\n","# <add your code here>\n","\n","## Compute the predictions for the test data and save it in a variable\n","## named y_pred_lasso\n","# <add your code here>"],"metadata":{"id":"XGVfAQHPsygV"},"id":"XGVfAQHPsygV","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Visualize the outputs(0.5 point)"],"metadata":{"id":"fI427Z-LIXTs"},"id":"fI427Z-LIXTs"},{"cell_type":"code","source":["## Let us visualize the regressors. We will create a single image containing\n","## two plots - one each for train and test set. Label the plots appropriately.\n","# <add your code here>"],"metadata":{"id":"yO_XpOmXsxbz"},"id":"yO_XpOmXsxbz","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Comment on the two models (0.5 point)\n","\n","\n","*  Is there any qualitative difference between the predictions from the plots?\n","*  Do you notice any difference in the optimal alpha values?\n","*  Do the weight vectors (coefficients) reveal anything?\n","\n","\n","\n","\n"],"metadata":{"id":"bD89Cod9tb7P"},"id":"bD89Cod9tb7P"},{"cell_type":"markdown","source":["# Cross Validation for Hyper-Parameter Tuning"],"metadata":{"id":"bW2UZ-YlBf4M"},"id":"bW2UZ-YlBf4M"},{"cell_type":"markdown","source":["# Loading a dataset part of the SKLearn Package (0.5 point)"],"metadata":{"id":"wtmlhTRtH3ot"},"id":"wtmlhTRtH3ot"},{"cell_type":"code","execution_count":null,"id":"9a41e141","metadata":{"id":"9a41e141"},"outputs":[],"source":["## We will use the diabetes dataset included as part of the sklearn package for this\n","## part of the lab. Write the necessary code to load the dataset into the workspace\n","## as a tuple consisting of the independent and dependent variable values\n","##\n","## Add a text block to describe the dataset\n","## - Number of data points\n","## - Number and list of attributes\n","## - Identify categorical (discrete) and continuous attributes\n","from sklearn import datasets\n","(X, y) = datasets.load_diabetes(return_X_y=True)"]},{"cell_type":"markdown","id":"e96f9638","metadata":{"id":"e96f9638"},"source":["# Grid Search CV (1.5 points)"]},{"cell_type":"code","execution_count":null,"id":"43d6d2d0","metadata":{"id":"43d6d2d0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662533385649,"user_tz":-330,"elapsed":400,"user":{"displayName":"Narayanan C Krishnan","userId":"15573189227140079431"}},"outputId":"1616c31a-1eea-4b65-82d9-36818e4d3b44"},"outputs":[{"output_type":"stream","name":"stdout","text":["ridge\n","Fitting 5 folds for each of 6 candidates, totalling 30 fits\n","[CV 1/5] END ...................alpha=1e-05;, score=-2779.958 total time=   0.0s\n","[CV 2/5] END ...................alpha=1e-05;, score=-3028.874 total time=   0.0s\n","[CV 3/5] END ...................alpha=1e-05;, score=-3237.588 total time=   0.0s\n","[CV 4/5] END ...................alpha=1e-05;, score=-3008.659 total time=   0.0s\n","[CV 5/5] END ...................alpha=1e-05;, score=-2910.266 total time=   0.0s\n","[CV 1/5] END ..................alpha=0.0001;, score=-2780.281 total time=   0.0s\n","[CV 2/5] END ..................alpha=0.0001;, score=-3029.146 total time=   0.0s\n","[CV 3/5] END ..................alpha=0.0001;, score=-3236.588 total time=   0.0s\n","[CV 4/5] END ..................alpha=0.0001;, score=-3008.383 total time=   0.0s\n","[CV 5/5] END ..................alpha=0.0001;, score=-2910.791 total time=   0.0s\n","[CV 1/5] END ...................alpha=0.001;, score=-2783.445 total time=   0.0s\n","[CV 2/5] END ...................alpha=0.001;, score=-3031.717 total time=   0.0s\n","[CV 3/5] END ...................alpha=0.001;, score=-3228.081 total time=   0.0s\n","[CV 4/5] END ...................alpha=0.001;, score=-3006.423 total time=   0.0s\n","[CV 5/5] END ...................alpha=0.001;, score=-2915.623 total time=   0.0s\n","[CV 1/5] END ....................alpha=0.01;, score=-2804.059 total time=   0.0s\n","[CV 2/5] END ....................alpha=0.01;, score=-3045.017 total time=   0.0s\n","[CV 3/5] END ....................alpha=0.01;, score=-3196.945 total time=   0.0s\n","[CV 4/5] END ....................alpha=0.01;, score=-3001.712 total time=   0.0s\n","[CV 5/5] END ....................alpha=0.01;, score=-2940.684 total time=   0.0s\n","[CV 1/5] END .....................alpha=0.1;, score=-2869.024 total time=   0.0s\n","[CV 2/5] END .....................alpha=0.1;, score=-3055.003 total time=   0.0s\n","[CV 3/5] END .....................alpha=0.1;, score=-3178.158 total time=   0.0s\n","[CV 4/5] END .....................alpha=0.1;, score=-2935.559 total time=   0.0s\n","[CV 5/5] END .....................alpha=0.1;, score=-2995.742 total time=   0.0s\n","[CV 1/5] END .......................alpha=1;, score=-3305.709 total time=   0.0s\n","[CV 2/5] END .......................alpha=1;, score=-3549.810 total time=   0.0s\n","[CV 3/5] END .......................alpha=1;, score=-3616.807 total time=   0.0s\n","[CV 4/5] END .......................alpha=1;, score=-3018.369 total time=   0.0s\n","[CV 5/5] END .......................alpha=1;, score=-3610.899 total time=   0.0s\n","\n","The List of best Parameters from the given tested parameters are:{'alpha': 0.0001}\n","--- 0.08219480514526367 seconds ---\n","{'alpha': 0.0001}\n","\n","lasso\n","Fitting 5 folds for each of 6 candidates, totalling 30 fits\n","[CV 1/5] END ...................alpha=1e-05;, score=-2779.951 total time=   0.0s\n","[CV 2/5] END ...................alpha=1e-05;, score=-3028.853 total time=   0.0s\n","[CV 3/5] END ...................alpha=1e-05;, score=-3237.642 total time=   0.0s\n","[CV 4/5] END ...................alpha=1e-05;, score=-3008.659 total time=   0.0s\n","[CV 5/5] END ...................alpha=1e-05;, score=-2910.252 total time=   0.0s\n","[CV 1/5] END ..................alpha=0.0001;, score=-2780.213 total time=   0.0s\n","[CV 2/5] END ..................alpha=0.0001;, score=-3028.944 total time=   0.0s\n","[CV 3/5] END ..................alpha=0.0001;, score=-3237.114 total time=   0.0s\n","[CV 4/5] END ..................alpha=0.0001;, score=-3008.370 total time=   0.0s\n","[CV 5/5] END ..................alpha=0.0001;, score=-2910.665 total time=   0.0s\n","[CV 1/5] END ...................alpha=0.001;, score=-2782.856 total time=   0.0s\n","[CV 2/5] END ...................alpha=0.001;, score=-3030.012 total time=   0.0s\n","[CV 3/5] END ...................alpha=0.001;, score=-3231.970 total time=   0.0s\n","[CV 4/5] END ...................alpha=0.001;, score=-3005.777 total time=   0.0s\n","[CV 5/5] END ...................alpha=0.001;, score=-2914.994 total time=   0.0s\n","[CV 1/5] END ....................alpha=0.01;, score=-2799.507 total time=   0.0s\n","[CV 2/5] END ....................alpha=0.01;, score=-3041.075 total time=   0.0s\n","[CV 3/5] END ....................alpha=0.01;, score=-3199.241 total time=   0.0s\n","[CV 4/5] END ....................alpha=0.01;, score=-3013.591 total time=   0.0s\n","[CV 5/5] END ....................alpha=0.01;, score=-2944.934 total time=   0.0s\n","[CV 1/5] END .....................alpha=0.1;, score=-2913.733 total time=   0.0s\n","[CV 2/5] END .....................alpha=0.1;, score=-3076.512 total time=   0.0s\n","[CV 3/5] END .....................alpha=0.1;, score=-3199.312 total time=   0.0s\n","[CV 4/5] END .....................alpha=0.1;, score=-2871.786 total time=   0.0s\n","[CV 5/5] END .....................alpha=0.1;, score=-2983.119 total time=   0.0s\n","[CV 1/5] END .......................alpha=1;, score=-3491.740 total time=   0.0s\n","[CV 2/5] END .......................alpha=1;, score=-4113.860 total time=   0.0s\n","[CV 3/5] END .......................alpha=1;, score=-4046.918 total time=   0.0s\n","[CV 4/5] END .......................alpha=1;, score=-3489.740 total time=   0.0s\n","[CV 5/5] END .......................alpha=1;, score=-4111.924 total time=   0.0s\n","\n","The List of best Parameters from the given tested parameters are:{'alpha': 0.0001}\n","--- 0.10752129554748535 seconds ---\n","{'alpha': 0.0001}\n","\n"]}],"source":["## We will use the grid search strategy along with cross validation to\n","## select the optimal hyper-parameter values for Ridge regression and LASSO.\n","## We will also measure the time spent for performing this search.\n","\n","# import that time package to call functions related to time measurement\n","import time\n","from sklearn.linear_model import Ridge, Lasso\n","from sklearn.model_selection import GridSearchCV\n","## Read the documentation for SKlearn model selection class GridSearchCV\n","## https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n","## Describe the following parameters and attributes of the class in your words.\n","## estimator:\n","##\n","## param_grid:\n","##\n","## refit:\n","##\n","## cv:\n","##\n","## scoring:\n","##\n","## cv_results_:\n","##\n","## best_estimator_:\n","##\n","## best_params_:\n","##\n","## \n","\n","# list of models we want to test\n","models = []\n","models.append(('ridge', Ridge()))\n","models.append(('lasso', Lasso()))\n","\n","## define a dictionary with hyper-parameter names as keys and a list of \n","## permissible values for the hyper-parameter\n","# <add your code here>\n","\n","# loop through the two models\n","for name, model in models:\n","    \n","    print(name) # print the model considered for grid search\n","    \n","    # create an instance of the GridSearchCV class for perorming a 5-fold CV to estimate the optimal value of alpha\n","    # scoring function should be negative mean squared error\n","    # use the default number of cross validation folds\n","    # set verbose to a level that will enable checking the intermediate outputs\n","    # <add your code here>\n","\n","    # note the time at the start of the search\n","    start_time = time.time()\n","\n","    # fitting the model for grid search\n","    # <add your code here>\n","\n","    # print best parameter after tuning\n","    # <add your code here>\n","    print(\"Time taken for hyper-parameter tuning is: %s seconds\" % (time.time() - start_time))\n","    print()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}